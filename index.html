<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image"/>
  <meta property="og:title" content="Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image"/>
  <meta property="og:description" content="Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image"/>
  <meta property="og:url" content="https://jerredchen.github.io/image-as-imu/"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Image as an IMU</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Image as an IMU: Estimating Camera Motion from a Single Motion-Blurred Image</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://jerredchen.github.io/" target="_blank">Jerred Chen</a><sup></sup>,</span>
                <span class="author-block">
                  <a href="https://www.ron-clark.com/" target="_blank">Ronald Clark</a><sup></sup></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Oxford<br>arXiv 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <!-- <a href="https://github.com/YOUR REPO HERE" target="_blank" -->
                    <a target="_blank"
                    class="external-link button is-disabled is-rounded is-normal is-dark">
                    <!-- class="external-link button is-normal is-rounded is-dark"> -->
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay muted loop width="100%">
        <!-- Your video here -->
        <source src="static/videos/teaser.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Given a single motion-blurred image, we predict the camera velocity at that instant.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In many robotics and VR/AR applications, fast camera motions cause a high level of motion blur, causing existing camera pose estimation methods to fail. In this work, we propose a novel framework that leverages motion blur as a rich cue for motion estimation rather than treating it as an unwanted artifact. Our approach works by predicting a dense motion flow field and a monocular depth map directly from a single motion-blurred image. We then recover the instantaneous camera velocity by solving a linear least squares problem under the small motion assumption. In essence, our method produces an IMU-like measurement that robustly captures fast and aggressive camera movements. To train our model, we construct a large-scale dataset with realistic synthetic motion blur derived from ScanNet++v2 and further refine our model by training end-to-end on real data using our fully differentiable pipeline. Extensive evaluations on real-world benchmarks demonstrate that our method achieves state-of-the-art angular and translational velocity estimates, outperforming current methods like MASt3R and COLMAP.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-centered has-text-centered">
      <h2 class="title is-3">Experimental Results</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <p>
              We evaluate our method on real-world motion-blurred videos. While our method is evaluated with one frame at a time, we compare against baselines with at least two images to compute the velocity. We directly treat the gyroscope readings as the angular velocity ground truth, and we approximate the translational velocity ground truth using the ARKit poses and framerate. Note that the angular velocity axes are x-up, y-left, z-backwards (using the IMU convention) whereas the the translational velocity axes are x-right, y-down, z-forward (using OpenCV convention).
            </p>
          </div>
        </div>
      </div>
      <div class="playback-controls has-text-centered mb-3">
        <button class="button is-small is-rounded is-info" id="speed-toggle">
          <span>Playback Speed: 0.25x</span>
        </button>
      </div>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/demo-cr.mov"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/demo-billiards-droid.mov"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/demo-office-colmap.mov"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const speedToggle = document.getElementById('speed-toggle');
      const videos = document.querySelectorAll('#results-carousel video');
      const speeds = [0.25, 0.5, 1.0];
      let currentSpeedIndex = 0;
      
      // Set initial playback rate
      videos.forEach(video => {
        video.playbackRate = speeds[currentSpeedIndex];
      });
      
      speedToggle.addEventListener('click', function() {
        currentSpeedIndex = (currentSpeedIndex + 1) % speeds.length;
        const newSpeed = speeds[currentSpeedIndex];
        
        videos.forEach(video => {
          video.playbackRate = newSpeed;
        });
        
        speedToggle.querySelector('span').textContent = `Playback Speed: ${newSpeed}x`;
      });
    });
  </script>
</section>
<!-- End video carousel -->

<!-- Animation. -->
<div class="columns is-centered">
  <div class="column is-three-fifths">
    <h2 class="title is-3">Animation</h2>

    <!-- Interpolating. -->
    <div class="content has-text-justified">
      <p>
        Try the animation by dragging the slider.
      </p>
    </div>
    <div class="columns is-vcentered animation-panel">
      <div class="column animation-video-column">
        <div id="animation-image-wrapper">
          Loading...
        </div>
        <input class="slider is-fullwidth is-large is-info"
                id="animation-slider"
                step="1" min="0" max="174" value="0" type="range">
      </div>
    </div>
    <br/>
    <!--/ Interpolating. -->

  </div>
</div>
<!--/ Animation. -->


<!-- Method -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Method Overview</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="item">
             <img src="static/images/blur_method.svg" alt="Method Overview">
          </div>
          <div class="content has-text-centered">
            <p> 
              Given a single image, our method predicts a dense motion flow field and a monocular depth map. We then recover the instantaneous camera velocity with linear least squares using the known exposure time and camera intrinsics.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End of method -->


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{chen2025_imageimu,
  title     = {{Image as an IMU}: Estimating Camera Motion from a Single Motion-Blurred Image},
  author    = {Chen, Jerred and Clark, Ronald},
  journal   = {arXiv preprint},
  year      = {2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
